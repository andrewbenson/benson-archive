<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="rgb(255,255,255)"><title>On the Proliferation of Artificial Intelligence &#183; Andrew Benson</title>
<meta name=title content="On the Proliferation of Artificial Intelligence &#183; Andrew Benson"><script type=text/javascript src=/js/appearance.min.022d0ebc3b46a335eb1c7ef79b7f2de143d7cd5156d433638592ef1ce5f8554e.js integrity="sha256-Ai0OvDtGozXrHH73m38t4UPXzVFW1DNjhZLvHOX4VU4="></script><link type=text/css rel=stylesheet href=/css/main.bundle.min.2dd44849efa9d0ef68e8cdede2901f86dec79026811f5cf6b25aa2b8cd8ee63e.css integrity="sha256-LdRISe+p0O9o6M3t4pAfht7HkCaBH1z2slqiuM2O5j4="><meta name=description content="
      
        Q: Do the benefits of artificial intelligence outweigh the risks?
      
    "><link rel=canonical href=https://benson.vc/posts/on-the-proliferation-of-artificial-intelligence/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:title" content="On the Proliferation of Artificial Intelligence"><meta property="og:description" content="Q: Do the benefits of artificial intelligence outweigh the risks?"><meta property="og:type" content="article"><meta property="og:url" content="https://benson.vc/posts/on-the-proliferation-of-artificial-intelligence/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-07-30T16:39:48-08:00"><meta property="article:modified_time" content="2018-07-30T16:39:48-08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="On the Proliferation of Artificial Intelligence"><meta name=twitter:description content="Q: Do the benefits of artificial intelligence outweigh the risks?"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"On the Proliferation of Artificial Intelligence","headline":"On the Proliferation of Artificial Intelligence","abstract":"Q: Do the benefits of artificial intelligence outweigh the risks?","inLanguage":"en","url":"https:\/\/benson.vc\/posts\/on-the-proliferation-of-artificial-intelligence\/","author":{"@type":"Person","name":"Andrew Benson"},"copyrightYear":"2018","dateCreated":"2018-07-30T16:39:48-08:00","datePublished":"2018-07-30T16:39:48-08:00","dateModified":"2018-07-30T16:39:48-08:00","mainEntityOfPage":"true","wordCount":"1620"}</script><meta name=author content="Andrew Benson"><link href=https://benson.vc/ rel=me><link href=https://github.com/andrewbenson rel=me><link href=https://linkedin.com/in/abenson rel=me><link href=https://twitter.com/andrewbenson rel=me></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold pe-2 text-primary-600 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 dark:text-neutral print:hidden sm:py-10"><nav class="flex items-start justify-between sm:items-center"><div class="flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>Andrew Benson</a></div><ul class="flex flex-col list-none text-end sm:flex-row"><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"></li></ul></nav></header><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header class=max-w-prose><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">On the Proliferation of Artificial Intelligence</h1><div class="mt-8 mb-12 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime="2018-07-30 16:39:48 -0800 -0800">July 30, 2018</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">8 mins</span></div></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="min-w-0 min-h-0 max-w-prose grow"><blockquote><p><strong>Q: Do the benefits of artificial intelligence outweigh the risks?</strong></p><p><em>The late physicist Stephen Hawking warned that artificial intelligence (AI) was “either the best or the worst thing ever to happen to humanity”. The technology promises to solve complex problems and unlock scientific mysteries. But it could also imperil jobs, make possible new kinds of weapons—and even develop beyond human control. Are such fears justified? How feasible is it to control the scale and speed of AI’s spread? And do the benefits outweigh the risks?</em></p></blockquote><p><em>This essay was originally submitted for <a href=https://www.economist.com/openfuture target=_blank rel=noreferrer>The Economist&rsquo;s OpenFuture Initiative</a>, a British publication. Hence, the UK grammar and use of the <a href=https://en.wikipedia.org/wiki/Classical%20liberalism target=_blank rel=noreferrer>UK&rsquo;s definition of &ldquo;liberal&rdquo; (often considered analogous to classic liberalism in the US)</a>.</em></p><p>While Artificial Intelligence (AI) promises unprecedented advances in healthcare, transportation, logistics, energy, manufacturing, human resources, marketing, finance, and agriculture, it is not without its risks or costs to society. The benefits that AI promises to deliver will outweigh the costs to society when the public risk posed by this set of emerging technologies is managed to ensure the benefits of AI are organized to capture value by balancing the interests of firms, individuals, and the public at-large.</p><p>Widespread public concern over how AI will impact jobs, economic inequality, and decision making has fueled the public’s fear of these technologies in recent years and shed light upon the larger issue of information asymmetry between the public, policy makers, and the AI research community. Concerns of other risks such as weaponized AI, algorithm bias, privacy abuses, or the possibility of an “AI takeover” due to the loss of human control over machines are not wholly unjustified and require the development of a normative consensus for how to best control the scope and scale of these emerging technologies. Without such a normative consensus, AI may become subject to unnecessary politicization (similar to how the environmental movement was in the US over the preceding 40 years) or be used as a means to accomplish illiberal ends, such as limiting the free expression of ideas and opinions.</p><p>The public’s paramount concern that AI and automation will result in sudden large scale job displacement is unwarranted. In <a href=https://www.oecd-ilibrary.org/social-issues-migration-health/the-risk-of-automation-for-jobs-in-oecd-countries_5jlz9h56dvq7-en target=_blank rel=noreferrer>a 2016 report</a>, the OECD estimated that 9% of the jobs in the US face high automatability as calculated using a job task model, concluding that <a href=https://www.oxfordmartin.ox.ac.uk/publications/view/1314 target=_blank rel=noreferrer>previously proposed research</a> had sharply overestimated the risk of automation to labour markets. Occupations, which consist of a set of tasks, are unlikely to be automated entirely due to engineering bottlenecks posed by certain job tasks. Rather, certain job tasks within occupations are susceptible to automation, which, when properly automated, may compliment the worker’s tasks. Such augmentation is expected to exert upward pressure on labour productivity and wage growth.</p><p>Structural changes to the division of labour are necessary for firms to fully realize the economic benefits of AI augmentation and enable human workers to exploit the engineering bottlenecks of automation by shifting their focus toward tasks that cannot be automated. Profit maximizing firms will make automation decisions by job task which requires the availability of sufficiently advanced technology as well as consideration of the relative factor prices of labour and capital. Due to the protracted adoption of automating the various job tasks within an occupation, labour-saving technology is unlikely to result in sudden large scale job losses as many predict. <a href=https://www.oecd-ilibrary.org/social-issues-migration-health/the-risk-of-automation-for-jobs-in-oecd-countries_5jlz9h56dvq7-en target=_blank rel=noreferrer>Some argue</a> that the increases in wages and creation of new occupations related to AI will partially, if not completely, offset the economic losses resulting from automation.</p><p>This is not to say that benefits of AI and automation will be shared broadly throughout the workforce. Workers in low skill occupations that consist of highly repetitive tasks and require little education face the greatest risk of automation and therefore disproportionally subject to persistent labour churn. With such workers being concentrated in rural areas, it is critical to balance the considerations of the geographic economic impact of automation with the aggregate economic impact. While the upcoming wave of automation is expected to produce a long run net gain to the economy as a whole, the gains will be concentrated in metropolitan areas with rural areas being left further behind. Without adequate consideration of the impact that AI weighs on non-metropolitan regions, the adoption of AI could exacerbate economic inequality with a transfer of wealth from the working class to the upper class and become subject to otherwise unnecessary politicization; thereby limiting the benefits that AI would bring to society.</p><p>As algorithms play a larger role in decision making, building automated systems that reflect human values and principles of equality and justice become of growing importance. Unchecked bias, whether implicit or overt, in the creation of algorithms is one of the greatest threats that artificial intelligence poses to humanity. Algorithm bias may result from implicit factors such as biased data sets used as inputs for machine learning algorithms or more overt factors such as the manipulation of algorithms by a developer for ideological or political motivations. A liberal case can be made for the need to foster greater representation of the presently under represented voices in the AI development workforce — for AI to best serve a diverse population, it must be created by a diverse population. Metrics to identify and correct algorithm bias must be created to provide reasonable assurance that the manifestation of AI does not result in biases along the dimensions of race, ethnicity, gender, religion, socioeconomic class, sexuality, geographic location, political identification, or ideology.</p><p>Viewpoint discrimination, resulting from biases in favor or in opposition to certain political identifications or ideologies, is a crucial but understudied variant of algorithm bias. A broadened definition of diversity that is inclusive of more abstract differences such as geographic upbringing, ideology, and economic background is necessary to serve the public good. The disenfranchised poor, often located in rural or agricultural regions, are not adequately represented in the development of AI — which is highly concentrated in coastal metropolitan areas. For AI to be widely accepted by the public, tech companies must shed the public’s perception of being leftist ideological echo chambers — and many big tech firms are currently working to do so. Facebook has recently removed their “Trending News” feature <a href=https://www.theverge.com/2018/6/1/17417428/facebook-trending-topics-being-removed target=_blank rel=noreferrer>in response to criticism</a> accusing the tech giant’s algorithm of being biased against conservatives. Without diverse participation in the creation of AI that is inclusive of diverse opinions, experiences, backgrounds, and identities, AI proliferation may lead to illiberal consequences and be viewed with skepticism by underrepresented groups thus giving way to its politicization.</p><p>Equipping AI with the use of force remains hotly contested — and for good reason. Last year, Elon Musk joined 115 other AI researchers in <a href=https://futureoflife.org/autonomous-weapons-open-letter-2017/ target=_blank rel=noreferrer>sending a letter to the United Nations</a> calling for a ban on the use of autonomous weapons. Others argue that autonomous weapons puts human soldiers further from harm’s way, possibly saving lives. Regardless, weaponized AI may pose an existential threat to humanity in the form of an AI weapon arms race, the use of extreme or unnecessary force to achieve a programmed objective, or a loss of human control of such weaponry. Lethal autonomous weapons further pose a challenge in their lack of accountability and therefore may be acceptable only in limited and specific use cases. The international community must quickly reach a normative consensus with respect to the development, use, and definition of lethal autonomous weaponry to control their proliferation.</p><p>Fears of malicious actors hacking or tampering autonomous systems are reasonably justified. Information security is a critical component to maintaining data and algorithm integrity, particularly in high risk contexts such as transportation, medical intervention, and weaponry. As the field of AI research and development matures, such risks should be mitigated through the creation and validation of safety standards, certifications, and governance frameworks. Governments and industry associations will need to play a role in the creation and enforcement of application specific standards to ensure instances are built and tested for safety.</p><p>In recent years, consumers have become more cognizant of the cost of their digital footprint and therefore more privacy conscious. The availability of big data is a key input for developing and improving AI learning. Machine learning algorithms analyze massive sets of data for classification and predictive modeling which serve as the foundation of AI. To balance the interests of consumers and firms, international standards should be developed for giving consumers notice of what personal data consumers provide to firms and how that data is used. To protect individual privacy rights, anonymized data sets are preferable for machine learning whenever possible.</p><p>AI will provide society with the capability to solve complex problems ranging from eliminating urban traffic congestion to finding a cure for cancer. However beneficial AI may be to society, safeguards must be put into place to control and govern AI in order to balance the interests of firms, individuals, and the public at-large. A broadened scope of computer ethics may be necessary to extend beyond how systems are used in practice to encompass ethical considerations of what and how systems are built. Something of a Hippocratic Oath for AI may be desired to provide reasonable assurance that “do no harm” supersedes when in conflict with another objective.</p><p>Just as AI can be used for societal good, it’s important to remember that AI can be used for illiberal reasons too — China has recently has made headlines in the West for using AI for domestic surveillance of dissidents and to censor online speech. Harnessing the power of AI should be confined to applications that do not violate individual rights or liberties. With sufficient mitigation of public risk by controlling the scope and scale of AI proliferation, AI can be a net benefit to society and ultimately worthwhile.</p></div></section><footer class="pt-8 max-w-prose print:hidden"><div class=flex><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Andrew Benson</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://benson.vc/ target=_blank aria-label=Link rel="me noopener noreferrer"><span class="relative inline-block align-text-bottom px-1 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentcolor" d="M172.5 131.1c55.6-55.59 148-55.59 203.6.0 50 50 57.4 129.7 16.3 187.2L391.3 319.9C381 334.2 361 337.6 346.7 327.3c-14.4-10.3-17.8-30.3-7.5-44.6L340.3 281.1C363.2 249 359.6 205.1 331.7 177.2c-31.4-31.4-82.5-31.4-114 0L105.5 289.5c-31.51 30.6-31.51 82.5.0 114C133.3 431.4 177.3 435 209.3 412.1L210.9 410.1C225.3 400.7 245.3 404 255.5 418.4 265.8 432.8 262.5 452.8 248.1 463.1L246.5 464.2c-58.4 41.1-136.3 34.5-186.29-15.4-56.469-56.5-56.469-148.1.0-204.5L172.5 131.1zM467.5 380c-56.5 56.5-148 56.5-204.5.0-50-50-56.5-128.8-15.4-186.3L248.7 192.1C258.1 177.8 278.1 174.4 293.3 184.7 307.7 194.1 311.1 214.1 300.8 229.3L299.7 230.9C276.8 262.1 280.4 306.9 308.3 334.8c31.4 31.4 82.5 31.4 114 0L534.5 222.5c31.5-31.5 31.5-83.4.0-114C506.7 80.63 462.7 76.99 430.7 99.9L429.1 101C414.7 111.3 394.7 107.1 384.5 93.58 374.2 79.2 377.5 59.21 391.9 48.94L393.5 47.82C451 6.731 529.8 13.25 579.8 63.24c56.5 56.46 56.5 148.06.0 204.46L467.5 380z"/></svg></span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://github.com/andrewbenson target=_blank aria-label=Github rel="me noopener noreferrer"><span class="relative inline-block align-text-bottom px-1 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://linkedin.com/in/abenson target=_blank aria-label=Linkedin rel="me noopener noreferrer"><span class="relative inline-block align-text-bottom px-1 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg></span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://twitter.com/andrewbenson target=_blank aria-label=X-Twitter rel="me noopener noreferrer"><span class="relative inline-block align-text-bottom px-1 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></span></a></div></div></div></div></footer></article><div class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2024
Andrew Benson</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://github.com/jpanther/congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="flex flex-row items-center"></div></div></footer></div></body></html>